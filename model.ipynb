{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\rahul.bhartari\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log read\n",
      "Total training samples: 28447\n",
      "Total validation samples: 7112\n",
      "./data/IMG/right_2016_12_01_13_41_48_305.jpg\n",
      "Sample dimensions: (160, 320, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x262ac0517f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x262a450cd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read images\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'nb_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-409f73e232bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;31m#model.add(Convolution2D(16, 9, 9, border_mode='same'))    # input: 80x320x1, output: 76x316x24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'elu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# input: 76x316x24, output: 38x158x24\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'nb_col'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Dropout, Activation, Cropping2D, Lambda\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Activation, Cropping2D, Lambda\n",
    "\n",
    "# Config: Modify when necessary\n",
    "data_root = './data'\n",
    "batch_size = 64\n",
    "EPOCHS = 7\n",
    "\n",
    "\n",
    "# read the driving log csv file\n",
    "samples = []\n",
    "csvfile = open(data_root+\"/driving_log.csv\")\n",
    "reader = csv.reader(csvfile)\n",
    "stear_correction = 0.3\n",
    "\n",
    "# merge all camera data into front camera data, adjust stear angle\n",
    "f = False\n",
    "for line in reader:\n",
    "    if not f:    # skip the first line, which does not contain any data\n",
    "        f = True\n",
    "        continue\n",
    "    steer = float(line[3])\n",
    "    samples.append([line[0], steer, False])\n",
    "    samples.append([line[1], steer+stear_correction, False])\n",
    "    samples.append([line[2], steer-stear_correction, False])\n",
    "    if -0.01 <= steer and steer >= 0.01:    # in case car is turning, also add the flipped version\n",
    "        samples.append([line[0], -steer, True])\n",
    "        samples.append([line[1], -steer-stear_correction, True])\n",
    "        samples.append([line[2], -steer+stear_correction, True])\n",
    "print(\"Log read\")\n",
    "csvfile.close()\n",
    "# shuffle the samples and split the training and validation sets\n",
    "samples = shuffle(samples)\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print(\"Total training samples:\", len(train_samples))\n",
    "print(\"Total validation samples:\", len(validation_samples))\n",
    "\n",
    "# display some stats\n",
    "ipath = data_root+'/IMG/'+train_samples[0][0].split('/')[-1]\n",
    "print(ipath)\n",
    "image = cv2.imread(ipath)\n",
    "print(\"Sample dimensions:\", image.shape)\n",
    "timg = cv2.flip(image, flipCode=1)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(timg)\n",
    "plt.show()\n",
    "### plot histogram to see steer data distribution ###\n",
    "#train_angles = []\n",
    "#for v in train_samples:\n",
    "#    train_angles.append(v[1])\n",
    "#plt.hist(train_angles, 50, normed=1, facecolor='green', alpha=0.75)\n",
    "#plt.xlabel('Steer Angle')\n",
    "#plt.ylabel('Frequency')\n",
    "#plt.show()\n",
    "#############################\n",
    "\n",
    "# function to generate data for the batch\n",
    "def generator(samples, batch_size=64):\n",
    "    pdir = data_root+'/IMG/'\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples,batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = pdir+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                if batch_sample[2]:    # if True then flip the image\n",
    "                    center_image = cv2.flip(center_image, flipCode=1)\n",
    "                center_angle = batch_sample[1]\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "            \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size)\n",
    "\n",
    "print(\"Read images\")\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "# Crop the image to remove unwanted area from the image\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160, 320, 3)))\n",
    "# Convert the image to grayscale, input format is BGR\n",
    "model.add(Lambda(lambda x:(0.163 * x[:,:,:,:1]) + (0.4870 * x[:,:,:,1:2]) + (0.35 * x[:,:,:,-1:])))\n",
    "# Normalize the data in image\n",
    "model.add(Lambda(lambda x:x/255))\n",
    "\n",
    "#model.add(Convolution2D(64, 7, 7, border_mode='same'))\n",
    "model.add(Conv2D(64, (7, 7), padding=\"same\"))        # input: 90x320x1, output: 90x320x64\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))       # input: 90x320x64, output: 45x160x64\n",
    "\n",
    "#model.add(Convolution2D(32, 5, 5, border_mode='valid'))\n",
    "model.add(Conv2D(32, (5, 5), padding=\"valid\"))        # input: 45x160x64, output: 41x156x32\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))       # input: 41x156x32, output: 19x78x32\n",
    "\n",
    "#model.add(Convolution2D(24, 3, 3, border_mode='valid'))\n",
    "model.add(Conv2D(24, (3, 3), padding=\"valid\"))        # input: 19x78x32, output: 17x76x24\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))       # input: 17x76x24, output: 9x38x24\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding=\"valid\"))        # input: 9x38x24, output: 7x36x16\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))       # input: 7x36x16, output: 4x18x16\n",
    "\n",
    "model.add(Flatten())            # input: 4x18x16, output: 1152\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(516))           # input: 1152, output: 516\n",
    "model.add(Activation('elu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))             # input: 516, output: 1\n",
    "print(\"Training\")\n",
    "\n",
    "# Train the model\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "#model.fit_generator(train_generator, samples_per_epoch= \\\n",
    "#            len(train_samples), validation_data=validation_generator, \\\n",
    "#            nb_val_samples=len(validation_samples), nb_epoch=7, verbose=1)\n",
    "model.fit_generator(train_generator, steps_per_epoch= len(train_samples)/batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=len(validation_samples)/batch_size, epochs=EPOCHS, verbose=1)\n",
    "print(\"Trained\")\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')\n",
    "print(\"Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
